!pip install numpy pandas matplotlib seaborn scikit-learn
# import the necessary packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import gridspec

#Load the File
file_path = r"creditcard.csv"
df = pd.read_csv(file_path)

# Display the first few rows of the DataFrame
df.head()
df.shape
df.describe()
# Determine number of fraud cases in dataset
fraud = df[df['Class'] == 1]
valid = df[df['Class'] == 0]
outlierFraction = len(fraud)/float(len(valid))
print(outlierFraction)
print('Fraud Cases: {}'.format(len(df[df['Class'] == 1])))
print('Valid Transactions: {}'.format(len(df[df['Class'] == 0])))
#printing amount details of fraud transactions
print("Amount details of the fraudulent transaction")
fraud.Amount.describe()
#printing amount details of normal transactions
print("details of valid transaction")
valid.Amount.describe()

As we can clearly notice from this, the average Money transaction for the fraudulent ones is more. This makes this problem crucial to deal with.
# Correlation matrix
corrmat = df.corr()
fig = plt.figure(figsize = (12, 9))
sns.heatmap(corrmat, vmax = .8, square = True)
plt.show()

V2 and V5 are highly negatively correlated with the feature called Amount. We also see some correlation with V20 and Amount. This gives us a deeper understanding of the Data available to us.
# dividing the X and the Y from the dataset
X = df.drop(['Class'], axis = 1)
Y = df["Class"]
print(X.shape)
print(Y.shape)
# getting just the values for the sake of processing
# (its a numpy array with no columns)
xData = X.values
yData = Y.values
# Using Scikit-learn to split data into training and testing sets
from sklearn.model_selection import train_test_split
# Split the data into training and testing sets
xTrain, xTest, yTrain, yTest = train_test_split(
		xData, yData, test_size = 0.2, random_state = 42)
Using Random forest as it handles imbalence well
# Building the Random Forest Classifier (RANDOM FOREST)
from sklearn.ensemble import RandomForestClassifier
# random forest model creation
rfc = RandomForestClassifier()
rfc.fit(xTrain, yTrain)
# predictions
yPred = rfc.predict(xTest)
# Evaluating the classifier
# printing every score of the classifier
# scoring in anything
from sklearn.metrics import classification_report, accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, matthews_corrcoef
from sklearn.metrics import confusion_matrix

n_outliers = len(fraud)
n_errors = (yPred != yTest).sum()
print("The model used is Random Forest classifier")

acc = accuracy_score(yTest, yPred)
print("The accuracy is {}".format(acc))

prec = precision_score(yTest, yPred)
print("The precision is {}".format(prec))

rec = recall_score(yTest, yPred)
print("The recall is {}".format(rec))

f1 = f1_score(yTest, yPred)
print("The F1-Score is {}".format(f1))

MCC = matthews_corrcoef(yTest, yPred)
print("The Matthews correlation coefficient is{}".format(MCC))
Confusion Matrix
# printing the confusion matrix
LABELS = ['Normal', 'Fraud']
conf_matrix = confusion_matrix(yTest, yPred)
plt.figure(figsize =(12, 12))
sns.heatmap(conf_matrix, xticklabels = LABELS,
			yticklabels = LABELS, annot = True, fmt ="d");
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()
# Create and train the Random Forest model with balanced class weights
rfc = RandomForestClassifier(class_weight='balanced')
rfc.fit(xTrain, yTrain)

# Make predictions
yPred = rfc.predict(xTest)

# Evaluate the model
print("Accuracy:", accuracy_score(yTest, yPred))
print("Classification Report:\n", classification_report(yTest, yPred))
acc = accuracy_score(yTest, yPred)
print("The accuracy is {}".format(acc))

prec = precision_score(yTest, yPred)
print("The precision is {}".format(prec))

rec = recall_score(yTest, yPred)
print("The recall is {}".format(rec))

f1 = f1_score(yTest, yPred)
print("The F1-Score is {}".format(f1))

MCC = matthews_corrcoef(yTest, yPred)
print("The Matthews correlation coefficient is{}".format(MCC))
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(class_weight='balanced')
lr.fit(xTrain, yTrain)
yPred = lr.predict(xTest)

print("Logistic Regression")
print("Accuracy:", accuracy_score(yTest, yPred))
print("Classification Report:\n", classification_report(yTest, yPred))

The results for Logistic Regression model indicate high accuracy but also highlight some important points:

Model Performance
Accuracy: 0.9679610968715986

This high accuracy is expected due to the class imbalance, where the majority class (valid transactions) dominates.
Precision, Recall, F1-score:

For Class 0 (Valid Transactions): The precision, recall, and F1-score are all very high, indicating the model performs well for the majority class.
For Class 1 (Fraudulent Transactions): The precision is very low (0.05), but the recall is very high (0.93). This means the model is good at identifying fraudulent transactions (high recall) but has many false positives (low precision). The F1-score is very low (0.09), reflecting the balance between precision and recall.
Macro and Weighted Averages:

The macro average gives equal weight to both classes, showing a lower overall performance.
The weighted average reflects the performance considering the imbalance, hence showing higher values for precision, recall, and F1-score.


Convergence Warning
The warning indicates that the logistic regression algorithm did not converge. This can be due to several reasons:

Number of Iterations: The default number of iterations might be too low.
Scaling Data: Logistic regression can perform better when features are scaled.
Solver: The default solver might not be the best for the data.
Improving Logistic Regression
The initial results show that the logistic regression model is highly accurate due to the class imbalance but struggles with precision for the minority class. By increasing the number of iterations, scaling the data, and trying different solvers, the model's performance and convergence can be improved
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Scale the data
scaler = StandardScaler()
xTrain_scaled = scaler.fit_transform(xTrain)
xTest_scaled = scaler.transform(xTest)

# Logistic Regression with increased max_iter and feature scaling
lr = LogisticRegression(class_weight='balanced', max_iter=1000, solver='liblinear')
lr.fit(xTrain_scaled, yTrain)
yPred = lr.predict(xTest_scaled)

print("Logistic Regression with Improved Parameters")
print("Accuracy:", accuracy_score(yTest, yPred))
print("Classification Report:\n", classification_report(yTest, yPred))
